{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GRU, Dense, Activation, Input, LSTM, TimeDistributed, Bidirectional, Lambda, Flatten, Permute, Concatenate, AvgPool2D\n",
    "from AttentionWithContext import AttentionWithContext\n",
    "from keras import backend as K\n",
    "from keras import optimizers as KO\n",
    "from keras import layers as KL\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Description: Seven Seq2Seq models with Bidirectional RNN\n",
    "####\n",
    "\n",
    "overall_encoder_input = Input(shape = (77, 6))\n",
    "overall_decoder_input = Input(shape = (7, 1))\n",
    "Outputs = []\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    # The first part is unchanged\n",
    "    encoder_inputs = Lambda(lambda x : x[:, 11 * i : 11 * (i + 1), :])(overall_encoder_input)\n",
    "    # Permute the matrix from (11, 6) to (6, 11) and apply the every input\n",
    "    p = Permute((2, 1))(encoder_inputs)\n",
    "    encoder_outputs_1, state_1_f, state_1_b = Bidirectional(GRU(64, return_state=True, return_sequences=True))(p)\n",
    "#     encoder_outputs_2, state_2_f, state_2_b = Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_1)\n",
    "#     encoder_outputs_3, state_3_f, state_3_b = Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_2)\n",
    "#     encoder_outputs_4, state_4_f, state_4_b = Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_3)\n",
    "\n",
    "    # Set up the decoder, which will only process one timestep at a time.\n",
    "    decoder_inputs = Lambda(lambda x : x[:, i : i + 1, :])(overall_decoder_input)\n",
    "    decoder_gru_1 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "#     decoder_gru_2 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "#     decoder_gru_3 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "#     decoder_gru_4 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "    decoder_dense_1 = Dense(64, activation='relu')\n",
    "    decoder_dense_2 = Dense(1, activation='relu')\n",
    "\n",
    "    all_outputs = []\n",
    "    inputs = decoder_inputs\n",
    "\n",
    "    for _ in range(6):\n",
    "        \n",
    "        # Run the decoder on one timestep\n",
    "        outputs, state_1_f, state_1_b = decoder_gru_1(inputs,  initial_state=(state_1_f, state_1_b))\n",
    "        \n",
    "        all_state_1_f = Lambda(lambda x : x[:, :, :64])(encoder_outputs_1)\n",
    "        attention_state_f = AttentionWithContext()(all_state_1_f)\n",
    "        all_state_1_b = Lambda(lambda x : x[:, :, 64:])(encoder_outputs_1)\n",
    "        attention_state_b = AttentionWithContext()(all_state_1_b)\n",
    "        \n",
    "        attention_state_f = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_f)\n",
    "        attention_state_b = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_b)\n",
    "        \n",
    "        outputs = Concatenate()([attention_state_f, attention_state_b, outputs])\n",
    "#         outputs, state_2_f, state_2_b = decoder_gru_2(outputs, initial_state=(state_2_f, state_2_b))\n",
    "#         outputs, state_3_f, state_3_b = decoder_gru_3(outputs, initial_state=(state_3_f, state_3_b))\n",
    "#         outputs, state_4_f, state_4_b = decoder_gru_3(outputs, initial_state=(state_4_f, state_4_b))\n",
    "        outputs = decoder_dense_1(outputs)\n",
    "        outputs = decoder_dense_2(outputs)\n",
    "        # Store the current prediction (we will concatenate all predictions later)\n",
    "        all_outputs.append(outputs)\n",
    "        # Reinject the outputs as inputs for the next loop iteration\n",
    "        # as well as update the states\n",
    "        inputs = outputs\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    decoder_outputs = Concatenate(axis = 1)(all_outputs)\n",
    "    Outputs.append(decoder_outputs)\n",
    "    \n",
    "cat = Concatenate(axis = 1)(Outputs)\n",
    "lstm_flat = Flatten()(cat)\n",
    "\n",
    "# Avg pooling the site map of the previous hour \n",
    "cnn_input = Input(shape=(11, 11, 1))\n",
    "avg_pool = AvgPool2D(pool_size=3, strides=2)(cnn_input)\n",
    "cnn_flat = Flatten()(avg_pool)\n",
    "\n",
    "# Concat all of them\n",
    "last_hr_pm25 = Input(shape=(1,))\n",
    "concat = Concatenate()([lstm_flat, cnn_flat, last_hr_pm25])\n",
    "dense = Dense(21, activation='relu')(concat)\n",
    "overall_output = Dense(6, activation='relu')(dense)\n",
    "\n",
    "# Define and compile model as previously\n",
    "model = Model([overall_encoder_input, overall_decoder_input, last_hr_pm25, cnn_input], overall_output)\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.save_weights('original_weights.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_cnn_site_map.pk', 'rb') as file:\n",
    "    cnn_site_map = pk.load(file)\n",
    "    \n",
    "with open('val_cnn_site_map.pk', 'rb') as file:\n",
    "    val_cnn_site_map = pk.load(file)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=2)\n",
    "    \n",
    "for i in range(77):\n",
    "\n",
    "    check_pointer = ModelCheckpoint(\"./Seq2Seq_with_attention/\"+ str(i + 1) + \".h5\", save_best_only=True)\n",
    "\n",
    "    training_data = np.load(\"./history_npy/\" + str(i + 1) + \".npy\")\n",
    "    label_data = np.load('./history_npy/' + str(i + 1) + '_label.npy')\n",
    "    \n",
    "    val_data = np.load('./history_npy/' + str(i + 1) + '_val.npy')\n",
    "    val_label_data = np.load('./history_npy/' + str(i + 1) + '_val_label.npy')\n",
    "    \n",
    "    last_hr_pm25_data = label_data[:, i]\n",
    "\n",
    "    training_data = training_data[1:]\n",
    "    label_data = label_data[1:]\n",
    "    last_hr_pm25_data = last_hr_pm25_data[:-1]\n",
    "\n",
    "    cnn_training = cnn_site_map[:, i]\n",
    "    cnn_training = np.expand_dims(cnn_training, axis = 3)\n",
    "    cnn_training = cnn_training[7:-6]\n",
    "\n",
    "    decoder_training_data = np.zeros((training_data.shape[0], 7, 1))\n",
    "\n",
    "    val_last_hr_pm25_data = val_label_data[:, i]\n",
    "\n",
    "    val_data = val_data[1:]\n",
    "    val_label_data = val_label_data[1:]\n",
    "    val_last_hr_pm25_data = val_last_hr_pm25_data[:-1]\n",
    "\n",
    "    cnn_val = val_cnn_site_map[:, i]\n",
    "    cnn_val = np.expand_dims(cnn_val, axis = 3)\n",
    "    cnn_val = cnn_val[7:-6]\n",
    "\n",
    "    decoder_val_data = np.zeros((val_data.shape[0], 7, 1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    model.load_weights('original_weights.h5')\n",
    "    model.fit([training_data, decoder_training_data, last_hr_pm25_data, cnn_training], \n",
    "              label_data, \n",
    "              batch_size=64, \n",
    "              epochs=50, \n",
    "              validation_data=([val_data, decoder_val_data, val_last_hr_pm25_data, cnn_val], val_label_data), \n",
    "              callbacks=[early_stopping, check_pointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_steps = range(12)\n",
    "s_steps = range(6, 12, 1)\n",
    "\n",
    "pred = model.predict([val_data, decoder_val_data, val_last_hr_pm25_data, cnn_val])\n",
    "\n",
    "result = np.zeros((6))\n",
    "\n",
    "for i in range(pred.shape[0]):\n",
    "    result += np.absolute(pred[i] - val_label_data[i])\n",
    "\n",
    "result /= pred.shape[0]\n",
    "result *= 500\n",
    "print(result)\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(s_steps, pred[i], 'b-', label='real')\n",
    "    ax.plot(t_steps, np.concatenate((label_data[-i], label_data[-i - 6]), axis = 0), 'r-', label='pred')\n",
    "    ax.set(xlabel=\"Hours\",ylabel=\"PM2.5\")\n",
    "    ax.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Description: Seven Seq2Seq models with Bidirectional RNN\n",
    "####\n",
    "\n",
    "encoder_inputs = Input(shape = (6, 77))\n",
    "decoder_inputs = Input(shape = (1, 1))\n",
    "Outputs = []\n",
    "    \n",
    "# The first part is unchanged\n",
    "# Permute the matrix from (11, 6) to (6, 11) and apply the every input\n",
    "encoder_outputs_1, state_1_f, state_1_b = Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_inputs)\n",
    "encoder_outputs_2, state_2_f, state_2_b = Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_1)\n",
    "encoder_outputs_3, state_3_f, state_3_b = Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_2)\n",
    "# encoder_outputs_4, state_4_f, state_4_b = Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_3)\n",
    "\n",
    "# Set up the decoder, which will only process one timestep at a time.\n",
    "decoder_gru_1 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_gru_2 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_gru_3 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "# decoder_gru_4 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_dense_1 = Dense(128, activation='relu')\n",
    "decoder_dense_2 = Dense(128, activation='relu')\n",
    "decoder_dense_3 = Dense(1, activation='relu')\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "inputs = decoder_inputs\n",
    "\n",
    "for _ in range(6):\n",
    "\n",
    "    # Run the decoder on one timestep\n",
    "    outputs, state_1_f, state_1_b = decoder_gru_1(inputs, initial_state=(state_1_f, state_1_b))\n",
    "\n",
    "    all_state_1_f = Lambda(lambda x : x[:, :, :64])(encoder_outputs_1)\n",
    "    attention_state_1_f = AttentionWithContext()(all_state_1_f)\n",
    "    all_state_1_b = Lambda(lambda x : x[:, :, 64:])(encoder_outputs_1)\n",
    "    attention_state_1_b = AttentionWithContext()(all_state_1_b)\n",
    "\n",
    "    attention_state_1_f = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_1_f)\n",
    "    attention_state_1_b = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_1_b)\n",
    "\n",
    "    outputs = Concatenate()([attention_state_1_f, attention_state_1_b, outputs])\n",
    "    outputs = decoder_dense_1(outputs)\n",
    "    \n",
    "    outputs, state_2_f, state_2_b = decoder_gru_2(outputs, initial_state=(state_2_f, state_2_b))\n",
    "    \n",
    "    all_state_2_f = Lambda(lambda x : x[:, :, :64])(encoder_outputs_1)\n",
    "    attention_state_2_f = AttentionWithContext()(all_state_2_f)\n",
    "    all_state_2_b = Lambda(lambda x : x[:, :, 64:])(encoder_outputs_1)\n",
    "    attention_state_2_b = AttentionWithContext()(all_state_2_b)\n",
    "\n",
    "    attention_state_2_f = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_2_f)\n",
    "    attention_state_2_b = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_2_b)\n",
    "    \n",
    "    outputs = Concatenate()([attention_state_2_f, attention_state_2_b, outputs])\n",
    "    outputs = decoder_dense_2(outputs)\n",
    "    \n",
    "    outputs, state_3_f, state_3_b = decoder_gru_2(outputs, initial_state=(state_3_f, state_3_b))\n",
    "    \n",
    "    all_state_3_f = Lambda(lambda x : x[:, :, :64])(encoder_outputs_1)\n",
    "    attention_state_3_f = AttentionWithContext()(all_state_3_f)\n",
    "    all_state_3_b = Lambda(lambda x : x[:, :, 64:])(encoder_outputs_1)\n",
    "    attention_state_3_b = AttentionWithContext()(all_state_3_b)\n",
    "\n",
    "    attention_state_3_f = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_3_f)\n",
    "    attention_state_3_b = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_3_b)\n",
    "    \n",
    "    outputs = Concatenate()([attention_state_3_f, attention_state_3_b, outputs])\n",
    "    outputs = decoder_dense_3(outputs)\n",
    "    \n",
    "    all_outputs.append(outputs)\n",
    "    inputs = outputs\n",
    "\n",
    "# Concatenate all predictions\n",
    "decoder_outputs = Concatenate(axis = 1)(all_outputs)\n",
    "\n",
    "lstm_flat = Flatten()(decoder_outputs)\n",
    "\n",
    "# Avg pooling the site map of the previous hour \n",
    "cnn_input = Input(shape=(11, 11, 1))\n",
    "avg_pool = AvgPool2D(pool_size=3, strides=2)(cnn_input)\n",
    "cnn_flat = Flatten()(avg_pool)\n",
    "\n",
    "# Concat all of them\n",
    "last_hr_pm25 = Input(shape=(1,))\n",
    "concat = Concatenate()([lstm_flat, cnn_flat, last_hr_pm25])\n",
    "dense = Dense(21, activation='relu')(concat)\n",
    "overall_output = Dense(6, activation='relu')(dense)\n",
    "\n",
    "# Define and compile model as previously\n",
    "model = Model([encoder_inputs, decoder_inputs, last_hr_pm25, cnn_input], overall_output)\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.save_weights('original_weights.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=2)\n",
    "\n",
    "training_data = np.load('./history_npy/1.npy')\n",
    "label_data = np.load('./history_npy/1_label.npy')\n",
    "\n",
    "with open('training_cnn_site_map.pk', 'rb') as file:\n",
    "    cnn_site_map = pk.load(file)\n",
    "\n",
    "last_hr_pm25_data = label_data[:, 0:1]\n",
    "\n",
    "training_data = training_data[1:]\n",
    "training_data = np.swapaxes(training_data, 1, 2)\n",
    "label_data = label_data[1:]\n",
    "last_hr_pm25_data = last_hr_pm25_data[:-1]\n",
    "\n",
    "cnn_training = cnn_site_map[:, 0]\n",
    "cnn_training = np.expand_dims(cnn_training, axis = 3)\n",
    "cnn_training = cnn_training[7:-6]\n",
    "\n",
    "decoder_training_data = np.expand_dims(last_hr_pm25_data, axis=1)\n",
    "\n",
    "val_data = np.load('./history_npy/1_val.npy')\n",
    "val_label_data = np.load('./history_npy/1_val_label.npy')\n",
    "\n",
    "with open('val_cnn_site_map.pk', 'rb') as file:\n",
    "    val_cnn_site_map = pk.load(file)\n",
    "\n",
    "val_last_hr_pm25_data = val_label_data[:, 0:1]\n",
    "\n",
    "val_data = val_data[1:]\n",
    "val_data = np.swapaxes(val_data, 1, 2)\n",
    "val_label_data = val_label_data[1:]\n",
    "val_last_hr_pm25_data = val_last_hr_pm25_data[:-1]\n",
    "\n",
    "cnn_val = val_cnn_site_map[:, 0]\n",
    "cnn_val = np.expand_dims(cnn_val, axis = 3)\n",
    "cnn_val = cnn_val[7:-6]\n",
    "\n",
    "decoder_val_data = np.expand_dims(val_last_hr_pm25_data, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.fit([training_data, decoder_training_data, last_hr_pm25_data, cnn_training], \n",
    "          label_data, \n",
    "          batch_size=64, \n",
    "          epochs=500, \n",
    "          validation_data=([val_data, decoder_val_data, val_last_hr_pm25_data, cnn_val], val_label_data), \n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Description: Seven Seq2Seq models with Bidirectional RNN\n",
    "####\n",
    "\n",
    "encoder_inputs = Input(shape = (6, 77))\n",
    "decoder_inputs = Input(shape = (1, 1))\n",
    "Outputs = []\n",
    "    \n",
    "# The first part is unchanged\n",
    "# Permute the matrix from (11, 6) to (6, 11) and apply the every input\n",
    "encoder_outputs_1, state_1_f, state_1_b = \\\n",
    "    Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_inputs)\n",
    "encoder_outputs_2, state_2_f, state_2_b = \\\n",
    "    Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_1)\n",
    "\n",
    "# Set up the decoder, which will only process one timestep at a time.\n",
    "decoder_gru_1 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_gru_2 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_dense = Dense(1, activation='relu')\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "inputs = decoder_inputs\n",
    "\n",
    "for _ in range(6):\n",
    "\n",
    "    # Run the decoder on one timestep\n",
    "    outputs, state_1_f, state_1_b = decoder_gru_1(inputs, initial_state=(state_1_f, state_1_b))\n",
    "    outputs, state_2_f, state_2_b = decoder_gru_2(outputs, initial_state=(state_2_f, state_2_b))\n",
    "\n",
    "    outputs = decoder_dense(outputs)\n",
    "    \n",
    "    all_outputs.append(outputs)\n",
    "    inputs = outputs\n",
    "\n",
    "# Concatenate all predictions\n",
    "decoder_outputs = Concatenate(axis = 1)(all_outputs)\n",
    "\n",
    "# Define and compile model as previously\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=KO.Adam(lr=1e-4), loss=\"mae\")\n",
    "#model.save_weights('original_weights.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([training_data, decoder_training_data], \n",
    "          np.expand_dims(label_data, axis=2), \n",
    "          batch_size=64, \n",
    "          epochs=500, \n",
    "          validation_data=([val_data, decoder_val_data], np.expand_dims(val_label_data, axis=2)), \n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 6\n",
    "\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = KL.Permute((2, 1))(inputs)\n",
    "    a = KL.Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = KL.Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    a_probs = KL.Permute((2, 1))(a)\n",
    "    output_attention_mul = KL.Multiply()([inputs, a_probs])\n",
    "    output_attention_sum = KL.Lambda(lambda x : K.sum(x, axis=1))(output_attention_mul)\n",
    "    return output_attention_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Description: Seven Seq2Seq models with Bidirectional RNN\n",
    "####\n",
    "\n",
    "encoder_inputs = Input(shape = (6, 77))\n",
    "decoder_inputs = Input(shape = (1, 1))\n",
    "Outputs = []\n",
    "    \n",
    "# The first part is unchanged\n",
    "# Permute the matrix from (11, 6) to (6, 11) and apply the every input\n",
    "encoder_outputs_1, state_1_f, state_1_b = \\\n",
    "    Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_inputs)\n",
    "encoder_outputs_2, state_2_f, state_2_b = \\\n",
    "    Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_1)\n",
    "encoder_outputs_3, state_3_f, state_3_b = \\\n",
    "    Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_2)\n",
    "encoder_outputs_4, state_4_f, state_4_b = \\\n",
    "    Bidirectional(GRU(64, return_state=True, return_sequences=True))(encoder_outputs_3)\n",
    "\n",
    "# Set up the decoder, which will only process one timestep at a time.\n",
    "decoder_gru_1 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_gru_2 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_gru_3 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_gru_4 = Bidirectional(GRU(64, return_sequences=True, return_state=True))\n",
    "decoder_dense = Dense(1, activation='relu')\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "inputs = decoder_inputs\n",
    "\n",
    "for _ in range(6):\n",
    "\n",
    "    # Run the decoder on one timestep\n",
    "    outputs, state_1_f, state_1_b = decoder_gru_1(inputs, initial_state=(state_1_f, state_1_b))\n",
    "\n",
    "    all_state_1_f = Lambda(lambda x : x[:, :, :64])(encoder_outputs_1)\n",
    "    attention_state_1_f = attention_3d_block(all_state_1_f)\n",
    "    all_state_1_b = Lambda(lambda x : x[:, :, 64:])(encoder_outputs_1)\n",
    "    attention_state_1_b = attention_3d_block(all_state_1_b)\n",
    "\n",
    "    attention_state_1_f = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_1_f)\n",
    "    attention_state_1_b = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_1_b)\n",
    "\n",
    "    outputs = Concatenate()([attention_state_1_f, attention_state_1_b, outputs])\n",
    "    \n",
    "    outputs, state_2_f, state_2_b = decoder_gru_2(outputs, initial_state=(state_2_f, state_2_b))\n",
    "    \n",
    "    all_state_2_f = Lambda(lambda x : x[:, :, :64])(encoder_outputs_2)\n",
    "    attention_state_2_f = AttentionWithContext()(all_state_2_f)\n",
    "    all_state_2_b = Lambda(lambda x : x[:, :, 64:])(encoder_outputs_2)\n",
    "    attention_state_2_b = AttentionWithContext()(all_state_2_b)\n",
    "\n",
    "    attention_state_2_f = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_2_f)\n",
    "    attention_state_2_b = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_2_b)\n",
    "    \n",
    "    outputs = Concatenate()([attention_state_2_f, attention_state_2_b, outputs])\n",
    "    \n",
    "    outputs, state_3_f, state_3_b = decoder_gru_3(outputs, initial_state=(state_3_f, state_3_b))\n",
    "    \n",
    "    all_state_3_f = Lambda(lambda x : x[:, :, :64])(encoder_outputs_3)\n",
    "    attention_state_3_f = AttentionWithContext()(all_state_3_f)\n",
    "    all_state_3_b = Lambda(lambda x : x[:, :, 64:])(encoder_outputs_3)\n",
    "    attention_state_3_b = AttentionWithContext()(all_state_3_b)\n",
    "\n",
    "    attention_state_3_f = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_3_f)\n",
    "    attention_state_3_b = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_3_b)\n",
    "    \n",
    "    outputs = Concatenate()([attention_state_3_f, attention_state_3_b, outputs])\n",
    "    \n",
    "    outputs, state_4_f, state_4_b = decoder_gru_4(outputs, initial_state=(state_4_f, state_4_b))\n",
    "    \n",
    "    all_state_4_f = Lambda(lambda x : x[:, :, :64])(encoder_outputs_4)\n",
    "    attention_state_4_f = AttentionWithContext()(all_state_4_f)\n",
    "    all_state_4_b = Lambda(lambda x : x[:, :, 64:])(encoder_outputs_4)\n",
    "    attention_state_4_b = AttentionWithContext()(all_state_4_b)\n",
    "\n",
    "    attention_state_4_f = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_4_f)\n",
    "    attention_state_4_b = Lambda(lambda x : K.expand_dims(x, axis=1))(attention_state_4_b)\n",
    "    \n",
    "    outputs = Concatenate()([attention_state_4_f, attention_state_4_b, outputs])\n",
    "\n",
    "    outputs = decoder_dense(outputs)\n",
    "    \n",
    "    all_outputs.append(outputs)\n",
    "    inputs = outputs\n",
    "\n",
    "# Concatenate all predictions\n",
    "decoder_outputs = Concatenate(axis = 1)(all_outputs)\n",
    "\n",
    "# Define and compile model as previously\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=KO.Adam(lr=1e-5), loss=\"mae\")\n",
    "#model.save_weights('original_weights.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([training_data, decoder_training_data], \n",
    "          np.expand_dims(label_data, axis=2), \n",
    "          batch_size=10240, \n",
    "          epochs=1000, \n",
    "          validation_data=([val_data, decoder_val_data], np.expand_dims(val_label_data, axis=2)), \n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([val_data, decoder_val_data], batch_size=val_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred - np.expand_dims(val_label_data, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.abs(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.mean(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result * 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
